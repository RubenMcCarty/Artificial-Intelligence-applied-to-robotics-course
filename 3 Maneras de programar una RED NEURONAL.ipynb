{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Maneras de Programar a una Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autor: Rubén Quispe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Creamos nuestros datos artificiales, donde buscaremos clasificar \n",
    "# dos anillos concéntricos de datos. \n",
    "X, Y = make_circles(n_samples=500, factor=0.5, noise=0.05)\n",
    "\n",
    "# Resolución del mapa de predicción.\n",
    "res = 100 \n",
    "\n",
    "# Coordendadas del mapa de predicción.\n",
    "_x0 = np.linspace(-1.5, 1.5, res)\n",
    "_x1 = np.linspace(-1.5, 1.5, res)\n",
    "\n",
    "# Input con cada combo de coordenadas del mapa de predicción.\n",
    "_pX = np.array(np.meshgrid(_x0, _x1)).T.reshape(-1, 2)\n",
    "\n",
    "# Objeto vacio a 0.5 del mapa de predicción.\n",
    "_pY = np.zeros((res, res)) + 0.5\n",
    "\n",
    "# Visualización del mapa de predicción.\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh(_x0, _x1, _pY, cmap=\"coolwarm\", vmin=0, vmax=1)\n",
    "\n",
    "# Visualización de la nube de datos.\n",
    "plt.scatter(X[Y == 0,0], X[Y == 0,1], c=\"skyblue\")\n",
    "plt.scatter(X[Y == 1,0], X[Y == 1,1], c=\"salmon\")\n",
    "\n",
    "plt.tick_params(labelbottom=False, labelleft=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0611342c2397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Definimos los puntos de entrada de la red, para la matriz X e Y.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0miX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0miY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    191\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m       \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import animation\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Definimos los puntos de entrada de la red, para la matriz X e Y.\n",
    "iX = tf.placeholder('float', shape=[None, X.shape[1]])\n",
    "iY = tf.placeholder('float', shape=[None])\n",
    "\n",
    "lr = 0.01           # learning rate\n",
    "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
    "\n",
    "# Capa 1\n",
    "W1 = tf.Variable(tf.random_normal([nn[0], nn[1]]), name='Weights_1')\n",
    "b1 = tf.Variable(tf.random_normal([nn[1]]), name='bias_1')\n",
    "\n",
    "l1 = tf.nn.relu(tf.add(tf.matmul(iX, W1), b1))\n",
    "\n",
    "# Capa 2\n",
    "W2 = tf.Variable(tf.random_normal([nn[1], nn[2]]), name='Weights_2')\n",
    "b2 = tf.Variable(tf.random_normal([nn[2]]), name='bias_2')\n",
    "\n",
    "l2 = tf.nn.relu(tf.add(tf.matmul(l1, W2), b2))\n",
    "\n",
    "# Capa 3\n",
    "W3 = tf.Variable(tf.random_normal([nn[2], nn[3]]), name='Weights_3')\n",
    "b3 = tf.Variable(tf.random_normal([nn[3]]), name='bias_3')\n",
    "\n",
    "# Vector de predicciones de Y.\n",
    "pY = tf.nn.sigmoid(tf.add(tf.matmul(l2, W3), b3))[:, 0]\n",
    "\n",
    "\n",
    "# Evaluación de las predicciones.\n",
    "loss = tf.losses.mean_squared_error(pY, iY)\n",
    "\n",
    "# Definimos al optimizador de la red, para que minimice el error.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)\n",
    "\n",
    "n_steps = 1000 # Número de ciclos de entrenamiento.\n",
    "\n",
    "iPY = [] # Aquí guardaremos la evolución de las predicción, para la animación.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  \n",
    "  # Inicializamos todos los parámetros de la red, las matrices W y b.\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "  # Iteramos n pases de entrenamiento.\n",
    "  for step in range(n_steps):\n",
    "  \n",
    "    # Evaluamos al optimizador, a la función de coste y al tensor de salida pY. \n",
    "    # La evaluación del optimizer producirá el entrenamiento de la red.\n",
    "    _, _loss, _pY = sess.run([optimizer, loss, pY], feed_dict={ iX : X, iY : Y })\n",
    "    \n",
    "    # Cada 25 iteraciones, imprimimos métricas.\n",
    "    if step % 25 == 0: \n",
    "      \n",
    "      # Cálculo del accuracy.\n",
    "      acc = np.mean(np.round(_pY) == Y)\n",
    "      \n",
    "      # Impresión de métricas.\n",
    "      print('Step', step, '/', n_steps, '- Loss = ', _loss, '- Acc =', acc)\n",
    "      \n",
    "      # Obtenemos predicciones para cada punto de nuestro mapa de predicción _pX.\n",
    "      _pY = sess.run(pY, feed_dict={ iX : _pX }).reshape((res, res))\n",
    "\n",
    "      # Y lo guardamos para visualizar la animación.\n",
    "      iPY.append(_pY)\n",
    "      \n",
    "  \n",
    "# ----- CÓDIGO ANIMACIÓN ----- #\n",
    "\n",
    "ims = []\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "print(\"--- Generando animación ---\")\n",
    "\n",
    "for fr in range(len(iPY)):\n",
    "  \n",
    "  im = plt.pcolormesh(_x0, _x1, iPY[fr], cmap=\"coolwarm\", animated=True)\n",
    "\n",
    "  # Visualización de la nube de datos.\n",
    "  plt.scatter(X[Y == 0,0], X[Y == 0,1], c=\"skyblue\")\n",
    "  plt.scatter(X[Y == 1,0], X[Y == 1,1], c=\"salmon\")\n",
    "\n",
    "  # plt.title(\"Resultado Clasificación\")\n",
    "  plt.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "  ims.append([im])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
    "\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RUBEN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RUBEN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 569us/sample - loss: 0.2501 - acc: 0.5040\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 57us/sample - loss: 0.2490 - acc: 0.5040\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.2480 - acc: 0.5160\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 55us/sample - loss: 0.2471 - acc: 0.5400\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 61us/sample - loss: 0.2461 - acc: 0.5500\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 61us/sample - loss: 0.2450 - acc: 0.5620\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 76us/sample - loss: 0.2441 - acc: 0.5740\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 67us/sample - loss: 0.2431 - acc: 0.6000\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.2421 - acc: 0.6120\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 57us/sample - loss: 0.2411 - acc: 0.6200\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 62us/sample - loss: 0.2401 - acc: 0.6260\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 58us/sample - loss: 0.2389 - acc: 0.6440\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 68us/sample - loss: 0.2377 - acc: 0.6580\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 59us/sample - loss: 0.2365 - acc: 0.6700\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 75us/sample - loss: 0.2353 - acc: 0.6940\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 60us/sample - loss: 0.2336 - acc: 0.7220\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.2318 - acc: 0.7380\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.2293 - acc: 0.7900\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 64us/sample - loss: 0.2260 - acc: 0.8480\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 61us/sample - loss: 0.2222 - acc: 0.8440\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 64us/sample - loss: 0.2183 - acc: 0.8560\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 79us/sample - loss: 0.2150 - acc: 0.8640\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.2123 - acc: 0.8620\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 60us/sample - loss: 0.2095 - acc: 0.8660\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 68us/sample - loss: 0.2066 - acc: 0.8760\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 59us/sample - loss: 0.2039 - acc: 0.8840\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 66us/sample - loss: 0.2010 - acc: 0.8920\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 54us/sample - loss: 0.1981 - acc: 0.9040\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.1951 - acc: 0.9100\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 56us/sample - loss: 0.1918 - acc: 0.9280\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 62us/sample - loss: 0.1886 - acc: 0.9280\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 58us/sample - loss: 0.1851 - acc: 0.9380\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 60us/sample - loss: 0.1817 - acc: 0.9400\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 58us/sample - loss: 0.1780 - acc: 0.9600\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 66us/sample - loss: 0.1742 - acc: 0.9660\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 65us/sample - loss: 0.1704 - acc: 0.9700\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 68us/sample - loss: 0.1663 - acc: 0.9860\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.1622 - acc: 0.9920\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 56us/sample - loss: 0.1579 - acc: 0.9960\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 65us/sample - loss: 0.1534 - acc: 0.9980\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 72us/sample - loss: 0.1491 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 72us/sample - loss: 0.1447 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 57us/sample - loss: 0.1398 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.1350 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 66us/sample - loss: 0.1305 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 61us/sample - loss: 0.1255 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 55us/sample - loss: 0.1206 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 66us/sample - loss: 0.1159 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 70us/sample - loss: 0.1112 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 68us/sample - loss: 0.1064 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 60us/sample - loss: 0.1017 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 64us/sample - loss: 0.0970 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 76us/sample - loss: 0.0925 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 75us/sample - loss: 0.0881 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 88us/sample - loss: 0.0838 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 72us/sample - loss: 0.0796 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 70us/sample - loss: 0.0757 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 56us/sample - loss: 0.0718 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 67us/sample - loss: 0.0681 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 64us/sample - loss: 0.0646 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 65us/sample - loss: 0.0612 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.0580 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 67us/sample - loss: 0.0551 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 68us/sample - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 55us/sample - loss: 0.0495 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 69us/sample - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 68us/sample - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 65us/sample - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 55us/sample - loss: 0.0404 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 69us/sample - loss: 0.0384 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 62us/sample - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 64us/sample - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 54us/sample - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 62us/sample - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 60us/sample - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 68us/sample - loss: 0.0291 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 68us/sample - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 59us/sample - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 69us/sample - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 52us/sample - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 61us/sample - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 64us/sample - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 72us/sample - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 60us/sample - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 62us/sample - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 60us/sample - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 62us/sample - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 59us/sample - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 61us/sample - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 64us/sample - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 66us/sample - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 61us/sample - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 60us/sample - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 62us/sample - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 66us/sample - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 59us/sample - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 57us/sample - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 62us/sample - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 60us/sample - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 65us/sample - loss: 0.0124 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d880906a48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "lr = 0.01           # learning rate\n",
    "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
    "\n",
    "\n",
    "# Creamos el objeto que contendrá a nuestra red neuronal, como\n",
    "# secuencia de capas.\n",
    "model = kr.Sequential()\n",
    "\n",
    "# Añadimos la capa 1\n",
    "l1 = model.add(kr.layers.Dense(nn[1], activation='relu'))\n",
    "\n",
    "# Añadimos la capa 2\n",
    "l2 = model.add(kr.layers.Dense(nn[2], activation='relu'))\n",
    "\n",
    "# Añadimos la capa 3\n",
    "l3 = model.add(kr.layers.Dense(nn[3], activation='sigmoid'))\n",
    "\n",
    "# Compilamos el modelo, definiendo la función de coste y el optimizador.\n",
    "model.compile(loss='mse', optimizer=kr.optimizers.SGD(lr=0.05), metrics=['acc'])\n",
    "\n",
    "# Y entrenamos al modelo. Los callbacks \n",
    "model.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.49019491\n",
      "Iteration 2, loss = 0.17163557\n",
      "Iteration 3, loss = 0.12897669\n",
      "Iteration 4, loss = 0.11729636\n",
      "Iteration 5, loss = 0.10813634\n",
      "Iteration 6, loss = 0.10422476\n",
      "Iteration 7, loss = 0.10000760\n",
      "Iteration 8, loss = 0.09603538\n",
      "Iteration 9, loss = 0.09232967\n",
      "Iteration 10, loss = 0.08863549\n",
      "Iteration 11, loss = 0.08526480\n",
      "Iteration 12, loss = 0.08136519\n",
      "Iteration 13, loss = 0.07762946\n",
      "Iteration 14, loss = 0.07300221\n",
      "Iteration 15, loss = 0.06829649\n",
      "Iteration 16, loss = 0.06335028\n",
      "Iteration 17, loss = 0.05825156\n",
      "Iteration 18, loss = 0.05271757\n",
      "Iteration 19, loss = 0.04713796\n",
      "Iteration 20, loss = 0.04151056\n",
      "Iteration 21, loss = 0.03601486\n",
      "Iteration 22, loss = 0.03017862\n",
      "Iteration 23, loss = 0.02497248\n",
      "Iteration 24, loss = 0.02026382\n",
      "Iteration 25, loss = 0.01631642\n",
      "Iteration 26, loss = 0.01348713\n",
      "Iteration 27, loss = 0.01132521\n",
      "Iteration 28, loss = 0.00975394\n",
      "Iteration 29, loss = 0.00872089\n",
      "Iteration 30, loss = 0.00796021\n",
      "Iteration 31, loss = 0.00740952\n",
      "Iteration 32, loss = 0.00691127\n",
      "Iteration 33, loss = 0.00658279\n",
      "Iteration 34, loss = 0.00629262\n",
      "Iteration 35, loss = 0.00615328\n",
      "Iteration 36, loss = 0.00569889\n",
      "Iteration 37, loss = 0.00550699\n",
      "Iteration 38, loss = 0.00527427\n",
      "Iteration 39, loss = 0.00511687\n",
      "Iteration 40, loss = 0.00499438\n",
      "Iteration 41, loss = 0.00486754\n",
      "Iteration 42, loss = 0.00476657\n",
      "Iteration 43, loss = 0.00460098\n",
      "Iteration 44, loss = 0.00446000\n",
      "Iteration 45, loss = 0.00438738\n",
      "Iteration 46, loss = 0.00430926\n",
      "Iteration 47, loss = 0.00423267\n",
      "Iteration 48, loss = 0.00419183\n",
      "Iteration 49, loss = 0.00413335\n",
      "Iteration 50, loss = 0.00411678\n",
      "Iteration 51, loss = 0.00402480\n",
      "Iteration 52, loss = 0.00400835\n",
      "Iteration 53, loss = 0.00405796\n",
      "Iteration 54, loss = 0.00397169\n",
      "Iteration 55, loss = 0.00393040\n",
      "Iteration 56, loss = 0.00390486\n",
      "Iteration 57, loss = 0.00388620\n",
      "Iteration 58, loss = 0.00387764\n",
      "Iteration 59, loss = 0.00383184\n",
      "Iteration 60, loss = 0.00382540\n",
      "Iteration 61, loss = 0.00379634\n",
      "Iteration 62, loss = 0.00379560\n",
      "Iteration 63, loss = 0.00377984\n",
      "Iteration 64, loss = 0.00376294\n",
      "Iteration 65, loss = 0.00375107\n",
      "Iteration 66, loss = 0.00373649\n",
      "Iteration 67, loss = 0.00373695\n",
      "Iteration 68, loss = 0.00372204\n",
      "Iteration 69, loss = 0.00370721\n",
      "Iteration 70, loss = 0.00369083\n",
      "Iteration 71, loss = 0.00366801\n",
      "Iteration 72, loss = 0.00364505\n",
      "Iteration 73, loss = 0.00364892\n",
      "Iteration 74, loss = 0.00364493\n",
      "Iteration 75, loss = 0.00365089\n",
      "Iteration 76, loss = 0.00363713\n",
      "Iteration 77, loss = 0.00361927\n",
      "Iteration 78, loss = 0.00362105\n",
      "Iteration 79, loss = 0.00361061\n",
      "Iteration 80, loss = 0.00361075\n",
      "Iteration 81, loss = 0.00359450\n",
      "Iteration 82, loss = 0.00358395\n",
      "Iteration 83, loss = 0.00357434\n",
      "Iteration 84, loss = 0.00356084\n",
      "Iteration 85, loss = 0.00355863\n",
      "Iteration 86, loss = 0.00356844\n",
      "Iteration 87, loss = 0.00359667\n",
      "Iteration 88, loss = 0.00353454\n",
      "Iteration 89, loss = 0.00355290\n",
      "Iteration 90, loss = 0.00352956\n",
      "Iteration 91, loss = 0.00352791\n",
      "Iteration 92, loss = 0.00352385\n",
      "Iteration 93, loss = 0.00353142\n",
      "Iteration 94, loss = 0.00352405\n",
      "Iteration 95, loss = 0.00349941\n",
      "Iteration 96, loss = 0.00351057\n",
      "Iteration 97, loss = 0.00350418\n",
      "Iteration 98, loss = 0.00351313\n",
      "Iteration 99, loss = 0.00349893\n",
      "Iteration 100, loss = 0.00348844\n",
      "Iteration 101, loss = 0.00348482\n",
      "Iteration 102, loss = 0.00350028\n",
      "Iteration 103, loss = 0.00351860\n",
      "Iteration 104, loss = 0.00349166\n",
      "Iteration 105, loss = 0.00348413\n",
      "Iteration 106, loss = 0.00350332\n",
      "Iteration 107, loss = 0.00346849\n",
      "Iteration 108, loss = 0.00347433\n",
      "Iteration 109, loss = 0.00350172\n",
      "Iteration 110, loss = 0.00344533\n",
      "Iteration 111, loss = 0.00346112\n",
      "Iteration 112, loss = 0.00346552\n",
      "Iteration 113, loss = 0.00343316\n",
      "Iteration 114, loss = 0.00345295\n",
      "Iteration 115, loss = 0.00344363\n",
      "Iteration 116, loss = 0.00343393\n",
      "Iteration 117, loss = 0.00342785\n",
      "Iteration 118, loss = 0.00343524\n",
      "Iteration 119, loss = 0.00347497\n",
      "Iteration 120, loss = 0.00342026\n",
      "Iteration 121, loss = 0.00344142\n",
      "Iteration 122, loss = 0.00343201\n",
      "Iteration 123, loss = 0.00341367\n",
      "Iteration 124, loss = 0.00343685\n",
      "Iteration 125, loss = 0.00340355\n",
      "Iteration 126, loss = 0.00339898\n",
      "Iteration 127, loss = 0.00340707\n",
      "Iteration 128, loss = 0.00341991\n",
      "Iteration 129, loss = 0.00337864\n",
      "Iteration 130, loss = 0.00338666\n",
      "Iteration 131, loss = 0.00337289\n",
      "Iteration 132, loss = 0.00337535\n",
      "Iteration 133, loss = 0.00337300\n",
      "Iteration 134, loss = 0.00337951\n",
      "Iteration 135, loss = 0.00336143\n",
      "Iteration 136, loss = 0.00338217\n",
      "Iteration 137, loss = 0.00336211\n",
      "Iteration 138, loss = 0.00336173\n",
      "Iteration 139, loss = 0.00335334\n",
      "Iteration 140, loss = 0.00334231\n",
      "Iteration 141, loss = 0.00336973\n",
      "Iteration 142, loss = 0.00336534\n",
      "Iteration 143, loss = 0.00334687\n",
      "Iteration 144, loss = 0.00334365\n",
      "Iteration 145, loss = 0.00334758\n",
      "Iteration 146, loss = 0.00334633\n",
      "Iteration 147, loss = 0.00334238\n",
      "Iteration 148, loss = 0.00331618\n",
      "Iteration 149, loss = 0.00333104\n",
      "Iteration 150, loss = 0.00333483\n",
      "Iteration 151, loss = 0.00332194\n",
      "Iteration 152, loss = 0.00332117\n",
      "Iteration 153, loss = 0.00332550\n",
      "Iteration 154, loss = 0.00330930\n",
      "Iteration 155, loss = 0.00333103\n",
      "Iteration 156, loss = 0.00330946\n",
      "Iteration 157, loss = 0.00330994\n",
      "Iteration 158, loss = 0.00328864\n",
      "Iteration 159, loss = 0.00332946\n",
      "Iteration 160, loss = 0.00331815\n",
      "Iteration 161, loss = 0.00329882\n",
      "Iteration 162, loss = 0.00328104\n",
      "Iteration 163, loss = 0.00328392\n",
      "Iteration 164, loss = 0.00328359\n",
      "Iteration 165, loss = 0.00330157\n",
      "Iteration 166, loss = 0.00329504\n",
      "Iteration 167, loss = 0.00326027\n",
      "Iteration 168, loss = 0.00327146\n",
      "Iteration 169, loss = 0.00328338\n",
      "Iteration 170, loss = 0.00324958\n",
      "Iteration 171, loss = 0.00325638\n",
      "Iteration 172, loss = 0.00325613\n",
      "Iteration 173, loss = 0.00324332\n",
      "Iteration 174, loss = 0.00324389\n",
      "Iteration 175, loss = 0.00322393\n",
      "Iteration 176, loss = 0.00323356\n",
      "Iteration 177, loss = 0.00323962\n",
      "Iteration 178, loss = 0.00323945\n",
      "Iteration 179, loss = 0.00322746\n",
      "Iteration 180, loss = 0.00322390\n",
      "Iteration 181, loss = 0.00320168\n",
      "Iteration 182, loss = 0.00323774\n",
      "Iteration 183, loss = 0.00323478\n",
      "Iteration 184, loss = 0.00320991\n",
      "Iteration 185, loss = 0.00321125\n",
      "Iteration 186, loss = 0.00320206\n",
      "Iteration 187, loss = 0.00320616\n",
      "Iteration 188, loss = 0.00323464\n",
      "Iteration 189, loss = 0.00319782\n",
      "Iteration 190, loss = 0.00320678\n",
      "Iteration 191, loss = 0.00320165\n",
      "Iteration 192, loss = 0.00319264\n",
      "Iteration 193, loss = 0.00318466\n",
      "Iteration 194, loss = 0.00318406\n",
      "Iteration 195, loss = 0.00316681\n",
      "Iteration 196, loss = 0.00315992\n",
      "Iteration 197, loss = 0.00318658\n",
      "Iteration 198, loss = 0.00316249\n",
      "Iteration 199, loss = 0.00318052\n",
      "Iteration 200, loss = 0.00316648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUBEN\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size=64, beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(16, 8, 1), learning_rate='constant',\n",
       "             learning_rate_init=0.01, max_iter=200, momentum=0.9,\n",
       "             n_iter_no_change=1000, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "import sklearn.neural_network\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "lr = 0.01           # learning rate\n",
    "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
    "\n",
    "# Creamos el objeto del modelo de red neuronal multicapa.\n",
    "clf = sk.neural_network.MLPRegressor(solver='sgd', \n",
    "                                     learning_rate_init=lr, \n",
    "                                     hidden_layer_sizes=tuple(nn[1:]),\n",
    "                                     verbose=True,\n",
    "                                     n_iter_no_change=1000,\n",
    "                                     batch_size = 64)\n",
    "\n",
    "\n",
    "# Y lo entrenamos con nuestro datos.\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
