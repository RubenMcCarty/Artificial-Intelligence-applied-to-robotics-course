{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de Dígitos MNIST.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autor: Mg. Rubén Quispe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versión de tensorflow: 1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"versión de tensorflow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](digitos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de ejemplos de entrenamiento: 55000\n",
      "Número de ejemplos de validación: 5000\n",
      "Número de ejemplos de prueba: 10000\n",
      "Tamaño de cada dígito: 784\n",
      "Tamaño de cada etiqueta: 10\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "### Los Ejemplos de entrenamiento están en: \n",
    "# mnist.train.images\n",
    "print(\"Número de ejemplos de entrenamiento:\", mnist.train.images.shape[0])\n",
    "\n",
    "### El conjunto de validacion es: \n",
    "# mnist.validation\n",
    "print(\"Número de ejemplos de validación:\", mnist.validation.images.shape[0])\n",
    "\n",
    "\n",
    "### El conjunto de prueba es: \n",
    "# mnist.test\n",
    "print(\"Número de ejemplos de prueba:\", mnist.test.images.shape[0])\n",
    "\n",
    "\n",
    "### Cada dígito es un vector de dimensión 784 .\n",
    "print(\"Tamaño de cada dígito:\", mnist.train.images.shape[1])\n",
    "\n",
    "\n",
    "### Las etiquetas se encuentran en: \n",
    "# mnist.train.labels\n",
    "# mnist.validation.labels\n",
    "# mnist.test.labels\n",
    "\n",
    "print(\"Tamaño de cada etiqueta:\", mnist.train.labels.shape[1])\n",
    "#Cada etiqueta es un one-hot-vector,ie. un vector con un solo uno, las demás entradas son cero\n",
    "#[1,0,0,0,0,0,0,0,0,0]  representa el número 0\n",
    "#[0,1,0,0,0,0,0,0,0,0]  representa el número 1\n",
    "#   .\n",
    "#   .\n",
    "#   ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muestra Digito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cada dígito se almacena como un vector de 784 dimensiones. Para visualizarlo, primero lo redimensionamos a una imagen de 28x28.\n",
    "def muestra_digito(x):\n",
    "    \"\"\"\n",
    "        x: vector \n",
    "            784 dimensiones\n",
    "        Muestra el vector como una imágen de 28x28\n",
    "    \"\"\"\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def vis_imagen(i, conjunto=\"train\"):\n",
    "    \"\"\"\n",
    "        i indice del conjunto especificado\n",
    "        conjunto: cadena\n",
    "            Cualquiera: train, validation, test\n",
    "            \n",
    "        Muestra el dígito en el indice i  y su etiqueta\n",
    "    \"\"\"\n",
    "    if(conjunto==\"train\"): \n",
    "        muestra_digito(mnist.train.images[i,])\n",
    "        label = np.argwhere(mnist.train.labels[i])[0][0]\n",
    "    elif(conjunto==\"test\"): \n",
    "        muestra_digito(mnist.test.images[i,])\n",
    "        label = np.argwhere(mnist.test.labels[i])[0][0]\n",
    "    else:\n",
    "        muestra_digito(mnist.validation.images[i,])\n",
    "        label = np.argwhere(mnist.validation.labels[i])[0][0]\n",
    "    print(\"Etiqueta \" + str(label))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAFKklEQVR4nO3dMUuVbRzH8XNX2NAryEk3oYZegK1BEDU4OIWz5eQilGsgNNraWKF7pIuDQ67iKkLQ3hAhlOb9bM907v95Hj15fic/n9Ef9/GAfLvACztN27Y9IM+1Ub8BoD9xQihxQihxQihxQqgb1dg0jV/lwh/Wtm3T7+tOTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTghVfgQgeRYXF8t9dXW13G/fvl3ua2trnduLFy/KZxkuJyeEEieEEieEEieEEieEEieEEieEcs85Ardu3ercqnvGXq/Xe/78ebm3bVvuJycn5X56etq53bx5s3z258+f5c7/4+SEUOKEUOKEUOKEUOKEUOKEUOKEUO45R2B6erpze/bs2R/93oPuQc/Ozjq369evD/vtUHByQihxQihxQihxQihxQihxQihXKVfMp0+fyn1vb69zOz4+HvbboeDkhFDihFDihFDihFDihFDihFDihFDuOUfgx48fndvHjx/LZx89enSh7725uVnu29vbF3p9hsfJCaHECaHECaHECaHECaHECaHECaHcc47Aly9fOrfHjx+Xz1b/dSV/FycnhBInhBInhBInhBInhBInhBInhHLPecU8efKk3D98+HBJ74RBnJwQSpwQSpwQSpwQSpwQSpwQSpwQqmnbtntsmu6RkRj095zVz7PXG/wZm/fv3+/c9vf3y2c5n7Ztm35fd3JCKHFCKHFCKHFCKHFCKHFCKFcpY+b169flvry8fKHXf/v2bee2tLRUPvvr168Lfe+rylUKjBlxQihxQihxQihxQihxQihxQij3nGPmzp075b61tVXuk5OT5/7eU1NT5f7169dzv/ZV5p4Txow4IZQ4IZQ4IZQ4IZQ4IZQ4IZR7zr/M7Oxsue/u7p77tZ8+fVru7969O/drX2XuOWHMiBNCiRNCiRNCiRNCiRNCiRNC3Rj1G+ByDfqIwMr8/Hy5u+ccLicnhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhPJfY/5lXr16Neq3wJA4OSGUOCGUOCGUOCGUOCGUOCGUOCGUe84xs7KyUu47OzvlPjs7W+7fv3/v3NbX18tnGS4nJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Rq2rbtHpume2Qkzs7Oyr36ef4Xa2trndvLly8v9Nr017Zt0+/rTk4IJU4IJU4IJU4IJU4IJU4I5U/GzuHevXvlvrCwUO4PHjzo3I6Ojspnm6bvb93/Negq5eTkpNwPDg7Kncvj5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ7jn7mJqaKve5ublyX1paKvdr17r/TZyZmSmfHXSPeXh4WO5v3rwp942NjXLn8jg5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdSVvOe8e/duuT98+LDcf//+Xe6np6flPjEx0bm9f/++fPbz58/lPuie8tu3b+VODicnhBInhBInhBInhBInhBInhBInhPIRgDBiPgIQxow4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IVT5EYDA6Dg5IZQ4IZQ4IZQ4IZQ4IZQ4IdQ/ksDRtvmtfFkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAFL0lEQVR4nO3dsUvUfxzH8fuGpuESDUG2uOQqSLQ1NOQqCP0DbtLgUg0hhDhKW39AY2OBs4OLS65BOms0iCA4tPT9zcF93+KpP1/nPR7jvbjjuzz7QB/Oa9q27QF57tz0AwD9iRNCiRNCiRNCiRNCjVVj0zT+KxeuWdu2Tb/XnZwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQqvwJQLiI2dnZct/d3S33k5OTzm1ubq5879nZWbkPIycnhBInhBInhBInhBInhBInhBInhHLPyZVZWVkp9/v375f70tJS5zY+Pj7QMw0zJyeEEieEEieEEieEEieEEieEEieEatq27R6bpntk5Lx7967c19fXy/3v37/lPjU1deFnug3atm36ve7khFDihFDihFDihFDihFDihFC+MsY/Hj582Lm9evWqfO/du3fLfW1tbaBnGlVOTgglTgglTgglTgglTgglTgglTgjlnpN/vH79unObn58v33t0dFTunz9/HuSRRpaTE0KJE0KJE0KJE0KJE0KJE0KJE0K55xwxjx49Kvfl5eXO7c6d+t/yg4ODcv/161e58y8nJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4RyzzliqnvMXq/Xm56e7tzO+wm/b9++DfRM9OfkhFDihFDihFDihFDihFDihFDihFBN27bdY9N0j0S6d+9euR8fH5f7xMRE57a5uVm+98OHD+X+58+fch9Vbds2/V53ckIocUIocUIocUIocUIocUIoXxm7Zd6/f1/uk5OT5V5drX39+rV8r6uSq+XkhFDihFDihFDihFDihFDihFDihFDuOYfMs2fPyv3NmzeX+vyPHz92bt+/f7/UZ3MxTk4IJU4IJU4IJU4IJU4IJU4IJU4I5U9jhhkbq6+et7a2yn1hYaHcf//+Xe5Pnz7t3A4PD8v3Mhh/GhOGjDghlDghlDghlDghlDghlDghlO9zhlleXi73ly9flnt1b93rnf93bd1l5nByQihxQihxQihxQihxQihxQihxQijf57wB1W9k7u/vl+99/Phxue/s7JT7ixcvyp3/n+9zwpARJ4QSJ4QSJ4QSJ4QSJ4TylbEb8OnTp87tvKuSHz9+lPvi4uJAz0QeJyeEEieEEieEEieEEieEEieEEieEcs95DR48eFDuz58/H/izt7e3y/309HTgzyaLkxNCiRNCiRNCiRNCiRNCiRNCiRNCuee8BisrK+X+5MmTzu3nz5/le1dXVwd6JoaPkxNCiRNCiRNCiRNCiRNCiRNCiRNCuee8BhsbG+Ve/ezily9frvpxGFJOTgglTgglTgglTgglTgglTgjlKqWPmZmZct/c3LzU5+/t7XVu1c8DMlqcnBBKnBBKnBBKnBBKnBBKnBBKnBDKPWcf591zLi0tXerz375927kdHx9f6rO5PZycEEqcEEqcEEqcEEqcEEqcEEqcEMo9Zx9HR0flfnJyUu5N05T74eHhhZ+J0ePkhFDihFDihFDihFDihFDihFDihFBN9XN0TdN0j8CVaNu278W4kxNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNClT8BCNwcJyeEEieEEieEEieEEieEEieE+g+HlrKTy3n2HgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 1\n"
     ]
    }
   ],
   "source": [
    "vis_imagen(0, conjunto=\"train\")\n",
    "vis_imagen(132, conjunto=\"validation\")\n",
    "vis_imagen(32, conjunto=\"test\")\n",
    "vis_imagen(50000, conjunto=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NEURONAL\n",
    "# Placeholders para los datos de entrenamiento\n",
    "# En ellos se pasaran despues los datos de entrenamiento (x,y)\n",
    "# x imagen, y etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784]) \n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Capa 1\n",
    "W_1 = tf.Variable(tf.truncated_normal(shape = [784,512], stddev=0.2))\n",
    "b_1 = tf.Variable(tf.zeros([512]))\n",
    "\n",
    "### Capa 2 de salida\n",
    "W_2 = tf.Variable(tf.truncated_normal(shape = [512,10], stddev=0.2))\n",
    "b_2 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura de Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(x):\n",
    "    \"\"\"\n",
    "        x: matriz\n",
    "            su forma  debe ser (m, 784)\n",
    "            \n",
    "        regresa la activación de la capa de salida\n",
    "        matriz de (m, 10)\n",
    "    \"\"\"\n",
    "    # Capa Escondida 1. \n",
    "    z_1 = tf.matmul(x,W_1) + b_1 ### Combinación lineal\n",
    "    a_1  = tf.nn.relu(z_1)     ### Activación (función no lineal)\n",
    "    \n",
    "    # Capa 2. Está es la capa de salida\n",
    "    z_2 = tf.matmul(a_1,W_2) + b_2 ### Combinación lineal\n",
    "    \n",
    "    return z_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = NN(x)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_, labels = y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = tf.nn.softmax(y_) # predicciones en el conjunto de entrenamiento\n",
    "### Nota: la función softmax calcula la probabilidad de cada etiqueta del 0 al 9.\n",
    "#Para obtener la predicción necesitamos usar las función tf.argmax(y_,1) o su versión en python np.argmax(y_,1)\n",
    "#Así se elige el dígito más probable para la imágen\n",
    "#Esto lo hace la función precision\n",
    "\n",
    "y_valid = NN(mnist.validation.images)\n",
    "valid_pred = tf.nn.softmax(y_valid) # predicciones en el conjunto de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesión de inicilaizador de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session() #Crea una sessión\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precisión\n",
    "def precision(predicciones, etiquetas):\n",
    "    return (100.0 * np.sum(np.argmax(predicciones, 1) == np.argmax(etiquetas, 1))\n",
    "          / predicciones.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:\n",
      "Costo del minibatch hasta el paso 0: 6.527097\n",
      "Precisión en el conjunto de entrenamiento: 6.0%\n",
      "Precision en el conjunto de validación: 31.3%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 500: 0.107576\n",
      "Precisión en el conjunto de entrenamiento: 95.0%\n",
      "Precision en el conjunto de validación: 96.0%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 1000: 0.056269\n",
      "Precisión en el conjunto de entrenamiento: 98.0%\n",
      "Precision en el conjunto de validación: 96.8%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 1500: 0.206266\n",
      "Precisión en el conjunto de entrenamiento: 93.0%\n",
      "Precision en el conjunto de validación: 97.0%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 2000: 0.019973\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.4%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 2500: 0.120382\n",
      "Precisión en el conjunto de entrenamiento: 96.0%\n",
      "Precision en el conjunto de validación: 97.4%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 3000: 0.017416\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.5%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 3500: 0.017765\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.8%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 4000: 0.019244\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.7%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 4500: 0.004923\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.8%\n",
      "\n",
      "\n",
      "Wall time: 42.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pasos = 5000\n",
    "\n",
    "print(\"Entrenamiento:\")\n",
    "for i in range(pasos):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    _,costo,predicciones =  sess.run([opt, cross_entropy, train_pred],  feed_dict={x: batch[0], y: batch[1]})\n",
    "    \n",
    "    if (i % 500 == 0):\n",
    "        print(\"Costo del minibatch hasta el paso %d: %f\" % (i, costo))\n",
    "        print(\"Precisión en el conjunto de entrenamiento: %.1f%%\" % precision(predicciones, batch[1]))\n",
    "        print(\"Precision en el conjunto de validación: %.1f%%\" % precision(\n",
    "        valid_pred.eval(session=sess), mnist.validation.labels))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de PRUEBA: 97.6%\n"
     ]
    }
   ],
   "source": [
    "y_test = NN(mnist.test.images)\n",
    "test_prediction = tf.nn.softmax(y_test)\n",
    "print(\"Precisión en el conjunto de PRUEBA: %.1f%%\" % precision(test_prediction.eval(session = sess), mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEyElEQVR4nO3cL2vVbQDH4Z0HX8IEwWIwyJJNhpoEg9FmEZPdYDAJvgHtKgaDRQwmYUXfgdEi+AdccQYtMpDfkx/w3DxuZzuf464r7ssZd/lww27OZtM0rQE9/yz7AMDviROixAlR4oQocULUsdE4m838KRcO2DRNs9/93M0JUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTog6tuwD8F+nT58e7k+ePBnu9+7dG+5bW1t/fCaWw80JUeKEKHFClDghSpwQJU6IEidEeeeMuXv37nC/cOHCcL9+/fpwf/PmzXDf3d0d7hweNydEiROixAlR4oQocUKUOCHKU0rM2bNnh/s0TcN9c3NzuG9sbAz3t2/fDncOj5sTosQJUeKEKHFClDghSpwQJU6I8s65Yr59+zbcnz59Otw/f/68yONwgNycECVOiBInRIkTosQJUeKEKHFClHfOFbO9vT3cv3//Ptx3dnYWeRwOkJsTosQJUeKEKHFClDghSpwQJU6I8s4Z8+jRo+F+//794X7ixIlFHoclcnNClDghSpwQJU6IEidEiROixAlR3jlj1tfX9/X5L1++LOgkLJubE6LECVHihChxQpQ4IUqcEOUpJWZ3d3dfn//58+eCTsKyuTkhSpwQJU6IEidEiROixAlR4oQo75wx+33nfPbs2YJOwrK5OSFKnBAlTogSJ0SJE6LECVHihCjvnEtw5syZudu1a9f29bvPnTs33Le2tvb1+zk8bk6IEidEiROixAlR4oQocUKUOCHKO+cSvHv3bu526dKl4We3t7eH+8bGxnD3zrk63JwQJU6IEidEiROixAlR4oQocUKUd86YnZ2d4f7q1atDOgnL5uaEKHFClDghSpwQJU6IEidEzaZpmj/OZvNHluLly5fD/fjx48N9c3NzkcdhAaZpmv3u525OiBInRIkTosQJUeKEKHFClDghylfGVsyvX7+G+8mTJ4f7+vr6cP/69esfn4mD4eaEKHFClDghSpwQJU6IEidEiROifJ9zxZw/f364v379erjfvn17uD948OBPj8Q++T4nrBhxQpQ4IUqcECVOiBInRIkTorxz/mU+ffo03D9+/DjcL168uMjj8D9454QVI06IEidEiROixAlR4oQo/xrzL/PixYvhfvPmzeF+6tSpuduHDx/2cCL2ys0JUeKEKHFClDghSpwQJU6IEidE+crYX+by5cvD/fnz58P98ePHc7dbt27t6UyM+coYrBhxQpQ4IUqcECVOiBInRIkTorxzHjF37twZ7jdu3Ji7XblyZfjZ9+/f7+VIR553Tlgx4oQocUKUOCFKnBAlTogSJ0R55zxiRv+Xdm1tbe3hw4dztx8/fgw/e/Xq1b0c6cjzzgkrRpwQJU6IEidEiROixAlR4oQo75ywZN45YcWIE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFq+K8xgeVxc0KUOCFKnBAlTogSJ0SJE6L+BaiPswp4szCpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 1\n"
     ]
    }
   ],
   "source": [
    "indice = 251\n",
    "p = tf.argmax(NN(mnist.test.images[indice:indice+1]).eval(session = sess),1)\n",
    "print(\"Predicción:\", sess.run(p)[0])\n",
    "vis_imagen(indice, conjunto=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_transparency(im, bg_colour=(255, 255, 255)):\n",
    "\n",
    "    # Only process if image has transparency \n",
    "    if im.mode in ('RGBA', 'LA') or (im.mode == 'P' and 'transparency' in im.info):\n",
    "\n",
    "        # Need to convert to RGBA if LA format due to a bug in PIL \n",
    "        alpha = im.convert('RGBA').split()[-1]\n",
    "\n",
    "        # Create a new background image of our matt color.\n",
    "        # Must be RGBA because paste requires both images have the same format\n",
    "\n",
    "        bg = Image.new(\"RGBA\", im.size, bg_colour + (255,))\n",
    "        bg.paste(im, mask=alpha)\n",
    "        return bg\n",
    "\n",
    "    else:\n",
    "        return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usa tu propia imágen\n",
    "# Cambia el nombre de de la variabel imagen por la tuya.\n",
    "# La imágen debe se una imágen cuadrada y cada dimensión mayor a 28.\n",
    "# Ej. una imágen de (512,512) en formato png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 756 into shape (1,784)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-a65eea590b5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mentrada\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mentrada\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentrada\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mentrada\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentrada\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 756 into shape (1,784)"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "imagen = \"imagen8.png\"\n",
    "img = Image.open(imagen)\n",
    "img = remove_transparency(img).convert('L')\n",
    "\n",
    "if  img.size != (28,28):\n",
    "    img.thumbnail((28,28), Image.ANTIALIAS)\n",
    "\n",
    "entrada = np.array(img, dtype = np.float32)\n",
    "entrada = entrada.reshape((1,784))\n",
    "entrada = entrada/255.0\n",
    "        \n",
    "p = tf.argmax(NN(entrada).eval(session = sess),1)\n",
    "print(\"Imágen:{}\".format(imagen))\n",
    "img.show()\n",
    "print(\"Predicción:\", sess.run(p)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
